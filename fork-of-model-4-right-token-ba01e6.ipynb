{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a983ab",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-11T07:42:44.897954Z",
     "iopub.status.busy": "2023-10-11T07:42:44.896971Z",
     "iopub.status.idle": "2023-10-11T07:43:51.256573Z",
     "shell.execute_reply": "2023-10-11T07:43:51.255297Z"
    },
    "papermill": {
     "duration": 66.368334,
     "end_time": "2023-10-11T07:43:51.258817",
     "exception": false,
     "start_time": "2023-10-11T07:42:44.890483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\r\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622383 sha256=eb4db05def6d87e95b3c40dcf066664787edb1f818bb47fa96dddb9d1cf1c6ae\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/69/42/0fb0421d2fe70d195a04665edc760cfe5fd341d7bb8d8e0aaa\r\n",
      "Successfully built autocorrect\r\n",
      "Installing collected packages: autocorrect\r\n",
      "Successfully installed autocorrect-2.6.1\r\n",
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b779bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:43:51.270269Z",
     "iopub.status.busy": "2023-10-11T07:43:51.269974Z",
     "iopub.status.idle": "2023-10-11T07:44:08.468402Z",
     "shell.execute_reply": "2023-10-11T07:44:08.467549Z"
    },
    "papermill": {
     "duration": 17.20645,
     "end_time": "2023-10-11T07:44:08.470492",
     "exception": false,
     "start_time": "2023-10-11T07:43:51.264042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from spellchecker import SpellChecker\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "disable_progress_bar()\n",
    "tqdm.pandas()\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=3407)\n",
    "DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d27922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:08.481607Z",
     "iopub.status.busy": "2023-10-11T07:44:08.480863Z",
     "iopub.status.idle": "2023-10-11T07:44:08.486064Z",
     "shell.execute_reply": "2023-10-11T07:44:08.485311Z"
    },
    "papermill": {
     "duration": 0.012357,
     "end_time": "2023-10-11T07:44:08.487735",
     "exception": false,
     "start_time": "2023-10-11T07:44:08.475378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name_1 = \"debertav3base\"\n",
    "    model_name_2 = \"debertav3large\"\n",
    "    model_name_3 = \"robertalarge\"\n",
    "    model_name_4 = \"debertav3huge\"#使用自己开源的huge版本\n",
    "    model_name_5 = \"debertav3base_single\"## 使用目前开源的最高分的baseline\n",
    "    \n",
    "    learning_rate=0.000015  #0.000015\n",
    "    weight_decay=0.03        #0.02\n",
    "    hidden_dropout_prob=0.1\n",
    "    attention_probs_dropout_prob=0.1\n",
    "    num_train_epochs=5\n",
    "    n_splits=4\n",
    "    batch_size=12\n",
    "    random_seed=42\n",
    "    save_steps=100\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1e240",
   "metadata": {
    "papermill": {
     "duration": 0.004248,
     "end_time": "2023-10-11T07:44:08.496457",
     "exception": false,
     "start_time": "2023-10-11T07:44:08.492209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1798a3b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:08.506798Z",
     "iopub.status.busy": "2023-10-11T07:44:08.506298Z",
     "iopub.status.idle": "2023-10-11T07:44:09.691654Z",
     "shell.execute_reply": "2023-10-11T07:44:09.690759Z"
    },
    "papermill": {
     "duration": 1.192991,
     "end_time": "2023-10-11T07:44:09.693816",
     "exception": false,
     "start_time": "2023-10-11T07:44:08.500825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                ) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.twd = TreebankWordDetokenizer()\n",
    "        self.STOP_WORDS = set(stopwords.words('english'))\n",
    "        \n",
    "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
    "        self.speller = Speller(lang='en')\n",
    "        self.spellchecker = SpellChecker() \n",
    "        \n",
    "    def word_overlap_count(self, row):\n",
    "        \"\"\" intersection(prompt_text, text) \"\"\"        \n",
    "        def check_is_stop_word(word):\n",
    "            return word in self.STOP_WORDS\n",
    "        \n",
    "        prompt_words = row['prompt_tokens']\n",
    "        summary_words = row['summary_tokens']\n",
    "        if self.STOP_WORDS:\n",
    "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "            \n",
    "    def ngrams(self, token, n):\n",
    "        # Use the zip function to help us generate n-grams\n",
    "        # Concatentate the tokens into ngrams and return\n",
    "        ngrams = zip(*[token[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "    def ngram_co_occurrence(self, row, n: int) -> int:\n",
    "        # Tokenize the original text and summary into words\n",
    "        original_tokens = row['prompt_tokens']\n",
    "        summary_tokens = row['summary_tokens']\n",
    "\n",
    "        # Generate n-grams for the original text and summary\n",
    "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
    "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
    "\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
    "        return len(common_ngrams)\n",
    "    \n",
    "    def ner_overlap_count(self, row, mode:str):\n",
    "        model = self.spacy_ner_model\n",
    "        def clean_ners(ner_list):\n",
    "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
    "        prompt = model(row['prompt_text'])\n",
    "        summary = model(row['text'])\n",
    "\n",
    "        if \"spacy\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
    "        elif \"stanza\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
    "        else:\n",
    "            raise Exception(\"Model not supported\")\n",
    "\n",
    "        prompt_ner = clean_ners(prompt_ner)\n",
    "        summary_ner = clean_ners(summary_ner)\n",
    "\n",
    "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
    "        \n",
    "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            return ner_dict\n",
    "        elif mode == \"test\":\n",
    "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
    "\n",
    "    \n",
    "    def quotes_count(self, row):\n",
    "        summary = row['text']\n",
    "        text = row['prompt_text']\n",
    "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
    "        if len(quotes_from_summary)>0:\n",
    "            return [quote in text for quote in quotes_from_summary].count(True)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def spelling(self, text):\n",
    "        \n",
    "        wordlist=text.split()\n",
    "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
    "\n",
    "        return amount_miss\n",
    "    \n",
    "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
    "        self.spellchecker.word_frequency.load_words(tokens)\n",
    "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
    "    \n",
    "    def run(self, \n",
    "            prompts: pd.DataFrame,\n",
    "            summaries:pd.DataFrame,\n",
    "            mode:str\n",
    "        ) -> pd.DataFrame:\n",
    "        \n",
    "        # before merge preprocess\n",
    "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "\n",
    "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "        \n",
    "        # Add prompt tokens into spelling checker dictionary\n",
    "        prompts[\"prompt_tokens\"].apply(\n",
    "            lambda x: self.add_spelling_dictionary(x)\n",
    "        )\n",
    "        \n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        # fix misspelling\n",
    "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n",
    "            lambda x: self.speller(x)\n",
    "        )\n",
    "        \n",
    "        # count misspelling\n",
    "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
    "        \n",
    "        # merge prompts and summaries\n",
    "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # after merge preprocess\n",
    "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
    "        \n",
    "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
    "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence,args=(2,), axis=1 \n",
    "        )\n",
    "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
    "        \n",
    "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence, args=(3,), axis=1\n",
    "        )\n",
    "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
    "        \n",
    "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
    "        \n",
    "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
    "    \n",
    "preprocessor = Preprocessor(model_name=CFG.model_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1439566d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:09.704454Z",
     "iopub.status.busy": "2023-10-11T07:44:09.704249Z",
     "iopub.status.idle": "2023-10-11T07:44:10.530516Z",
     "shell.execute_reply": "2023-10-11T07:44:10.529554Z"
    },
    "papermill": {
     "duration": 0.833628,
     "end_time": "2023-10-11T07:44:10.532301",
     "exception": false,
     "start_time": "2023-10-11T07:44:09.698673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3350.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 6288.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2498.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2706.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2582.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2492.53it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/pre-process/train.csv')\n",
    "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be22dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:10.544878Z",
     "iopub.status.busy": "2023-10-11T07:44:10.544496Z",
     "iopub.status.idle": "2023-10-11T07:44:10.557144Z",
     "shell.execute_reply": "2023-10-11T07:44:10.556362Z"
    },
    "papermill": {
     "duration": 0.020928,
     "end_time": "2023-10-11T07:44:10.558951",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.538023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b359a980",
   "metadata": {
    "papermill": {
     "duration": 0.005463,
     "end_time": "2023-10-11T07:44:10.569696",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.564233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31cb889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:10.582202Z",
     "iopub.status.busy": "2023-10-11T07:44:10.581725Z",
     "iopub.status.idle": "2023-10-11T07:44:10.587922Z",
     "shell.execute_reply": "2023-10-11T07:44:10.587231Z"
    },
    "papermill": {
     "duration": 0.014691,
     "end_time": "2023-10-11T07:44:10.589607",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.574916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb081aeb",
   "metadata": {
    "papermill": {
     "duration": 0.005097,
     "end_time": "2023-10-11T07:44:10.600396",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.595299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deberta Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edef5495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:10.612308Z",
     "iopub.status.busy": "2023-10-11T07:44:10.612142Z",
     "iopub.status.idle": "2023-10-11T07:44:10.626973Z",
     "shell.execute_reply": "2023-10-11T07:44:10.625950Z"
    },
    "papermill": {
     "duration": 0.023088,
     "end_time": "2023-10-11T07:44:10.628622",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.605534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentScoreRegressor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                model_dir: str,\n",
    "                target: str,\n",
    "                hidden_dropout_prob: float,\n",
    "                attention_probs_dropout_prob: float,\n",
    "                max_length: int,\n",
    "                ):\n",
    "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
    "        self.input_col = \"input\"\n",
    "        \n",
    "        self.text_cols = [self.input_col] \n",
    "        self.target = target\n",
    "        self.target_cols = [target]\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "        if model_name==\"debertav3base\":\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/debertav3base\")\n",
    "            self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/debertav3base\")\n",
    "        if model_name==\"debertav3large\":\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/debertav3large\")\n",
    "            self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/debertav3large\")\n",
    "        if model_name==\"robertalarge\":\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/d/julian3833/robertalarge\")\n",
    "            self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/d/julian3833/robertalarge\")# /kaggle/input/robertalarge\n",
    "        if model_name==\"debertav3huge\":\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/debertav3large\")\n",
    "            self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/debertav3large\")\n",
    "        if model_name==\"debertav3base_single\":\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/debertav3base\")\n",
    "            self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/debertav3base\")\n",
    "        \n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
    "            \"num_labels\": 1,\n",
    "            \"problem_type\": \"regression\",\n",
    "        })\n",
    "        \n",
    "        seed_everything(seed=3407)\n",
    "\n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[self.target]]\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return tokenized\n",
    "\n",
    "        \n",
    "    def predict(self, \n",
    "                test_df: pd.DataFrame,\n",
    "                fold: int,\n",
    "               ):\n",
    "        \"\"\"predict content score\"\"\"\n",
    "        \n",
    "        sep = self.tokenizer.sep_token\n",
    "        in_text = (\n",
    "                    test_df[\"prompt_title\"] + sep \n",
    "                    + test_df[\"prompt_question\"] + sep \n",
    "                    + test_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        test_df[self.input_col] = in_text\n",
    "\n",
    "        test_ = test_df[[self.input_col]]\n",
    "    \n",
    "        test_dataset = Dataset.from_pandas(test_, preserve_index=False) \n",
    "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
    "        model_content.eval()\n",
    "        \n",
    "        # e.g. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train = False,\n",
    "            do_predict = True,\n",
    "            per_device_eval_batch_size = 8,   \n",
    "            dataloader_drop_last = False,\n",
    "        )\n",
    "\n",
    "        # init trainer\n",
    "        infer_content = Trainer(\n",
    "                      model = model_content, \n",
    "                      tokenizer=self.tokenizer,\n",
    "                      data_collator=self.data_collator,\n",
    "                      args = test_args)\n",
    "\n",
    "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c326530a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:10.640304Z",
     "iopub.status.busy": "2023-10-11T07:44:10.640136Z",
     "iopub.status.idle": "2023-10-11T07:44:10.650125Z",
     "shell.execute_reply": "2023-10-11T07:44:10.649270Z"
    },
    "papermill": {
     "duration": 0.017946,
     "end_time": "2023-10-11T07:44:10.651774",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.633828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"predict oof data\"\"\"\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            if model_name==\"debertav3large\":\n",
    "                model_dir =  f\"/kaggle/input/debertav3large-{target}-fold-{fold}/{target}/\"\n",
    "            if model_name==\"debertav3base\" and target==\"content\" :\n",
    "                model_dir =  f\"/kaggle/input/debertav3base-{target}-trainonly/{target}/{model_name}/fold_{fold}/\"\n",
    "            if model_name==\"debertav3base\" and target==\"wording\" :\n",
    "                model_dir =  f\"/kaggle/input/debertav3base-{target}-trainonly/{model_name}/fold_{fold}/\"\n",
    "            if model_name==\"robertalarge\":\n",
    "                model_dir = f\"/kaggle/input/robertalarge-{target}-{fold}/fold_{fold}\"\n",
    "                \n",
    "            if model_name == 'debertav3huge':\n",
    "                model_dir = f\"/kaggle/input/debertav3large-huge/{target}/{target}/debertav3large/fold_{fold}\"\n",
    "        #最后使用的开源的最高分的是用的base没有分target版本\n",
    "        if save_each_model == False:\n",
    "            model_dir = f\"/kaggle/input/commonlistdebertatuned/debertav3base/fold_{fold}\"\n",
    " \n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=valid_data, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        train_df.loc[valid_data.index, f\"{target}_{model_name}\"] = pred\n",
    "\n",
    "    return train_df\n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ):\n",
    "    \"\"\"predict using mean folds\"\"\"\n",
    "    #模型名称是model_name\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        if save_each_model == True:\n",
    "            if model_name==\"debertav3large\":\n",
    "                model_dir =  f\"/kaggle/input/debertav3large-{target}-fold-{fold}/{target}/\"\n",
    "            if model_name==\"debertav3base\" and target==\"content\" :\n",
    "                model_dir =  f\"/kaggle/input/debertav3base-{target}-trainonly/{target}/{model_name}/fold_{fold}/\"\n",
    "            if model_name==\"debertav3base\" and target==\"wording\" :\n",
    "                model_dir =  f\"/kaggle/input/debertav3base-{target}-trainonly/{model_name}/fold_{fold}/\"\n",
    "            if model_name==\"robertalarge\":\n",
    "                model_dir = f\"/kaggle/input/robertalarge-{target}-{fold}/fold_{fold}\"\n",
    "                \n",
    "                \n",
    "            if model_name == 'debertav3huge':\n",
    "                model_dir = f\"/kaggle/input/debertav3large-huge/{target}/{target}/debertav3large/fold_{fold}\"\n",
    "        #最后使用的开源的最高分的是用的base没有分target版本\n",
    "        if save_each_model == False:\n",
    "            model_dir = f\"/kaggle/input/commonlistdebertatuned/debertav3base/fold_{fold}\"\n",
    "    \n",
    "                \n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=test_df, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        test_df[f\"{target}_{model_name}_{fold}\"] = pred\n",
    "    \n",
    "    test_df[f\"{target}_{model_name}\"] = test_df[[f\"{target}_{model_name}_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904acc01",
   "metadata": {
    "papermill": {
     "duration": 0.005294,
     "end_time": "2023-10-11T07:44:10.662234",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.656940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型推断部分 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e5efd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:10.673960Z",
     "iopub.status.busy": "2023-10-11T07:44:10.673396Z",
     "iopub.status.idle": "2023-10-11T07:44:10.677176Z",
     "shell.execute_reply": "2023-10-11T07:44:10.676350Z"
    },
    "papermill": {
     "duration": 0.011518,
     "end_time": "2023-10-11T07:44:10.678925",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.667407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5407728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T07:44:10.690503Z",
     "iopub.status.busy": "2023-10-11T07:44:10.690330Z",
     "iopub.status.idle": "2023-10-11T08:25:21.012515Z",
     "shell.execute_reply": "2023-10-11T08:25:21.010066Z"
    },
    "papermill": {
     "duration": 2470.332695,
     "end_time": "2023-10-11T08:25:21.016745",
     "exception": false,
     "start_time": "2023-10-11T07:44:10.684050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是debertav3base_content的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv content rmse: 0.48438723597753275\n",
      "现在是debertav3base_content的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是debertav3large_content的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv content rmse: 0.4507416519114946\n",
      "现在是debertav3large_content的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是robertalarge_content的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv content rmse: 0.5072132849954926\n",
      "现在是robertalarge_content的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是debertav3huge_content的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv content rmse: 0.4758927439896877\n",
      "现在是debertav3huge_content的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是debertav3base_wording的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv wording rmse: 0.6263381693156309\n",
      "现在是debertav3base_wording的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是debertav3large_wording的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv wording rmse: 0.6624682560141111\n",
      "现在是debertav3large_wording的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是robertalarge_wording的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv wording rmse: 0.6855003321456917\n",
      "现在是robertalarge_wording的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "现在是debertav3huge_wording的validate\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv wording rmse: 0.6472189480549035\n",
      "现在是debertav3huge_wording的test\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "耗时 -2470.3072044849396\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for target in [\"content\",\"wording\"]:\n",
    "###############################------model_name_1------#####################################################\n",
    "    print('*'*30)\n",
    "   \n",
    "    print(f'现在是{CFG.model_name_1}_{target}的validate')\n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_1,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_{CFG.model_name_1}\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "    print(f'现在是{CFG.model_name_1}_{target}的test')\n",
    "    \n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_1,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "###################################------model_name_2------#################################################\n",
    "    print('*'*30)\n",
    "\n",
    "    #model2\n",
    "    print(f'现在是{CFG.model_name_2}_{target}的validate')\n",
    "    \n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_2,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_{CFG.model_name_2}\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "    print(f'现在是{CFG.model_name_2}_{target}的test')\n",
    "    \n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_2,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "#######################################------model_name_3------#############################################\n",
    "    print('*'*30)\n",
    "    \n",
    "    #model3\n",
    "    print(f'现在是{CFG.model_name_3}_{target}的validate')\n",
    "    \n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_3,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_{CFG.model_name_3}\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "    print(f'现在是{CFG.model_name_3}_{target}的test')\n",
    "    \n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_3,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "#######################################------model_name_4------#############################################\n",
    "    print('*'*30)\n",
    "\n",
    "    print(f'现在是{CFG.model_name_4}_{target}的validate')\n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_4,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_{CFG.model_name_4}\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "    print(f'现在是{CFG.model_name_4}_{target}的test')\n",
    "    \n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name_4,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "################################------model_name_5------####################################################\n",
    "\n",
    "over_tiem =time.time()\n",
    "print(\"耗时\",start_time-over_tiem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77042787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T08:25:21.044123Z",
     "iopub.status.busy": "2023-10-11T08:25:21.043912Z",
     "iopub.status.idle": "2023-10-11T08:25:21.052971Z",
     "shell.execute_reply": "2023-10-11T08:25:21.052189Z"
    },
    "papermill": {
     "duration": 0.025007,
     "end_time": "2023-10-11T08:25:21.054583",
     "exception": false,
     "start_time": "2023-10-11T08:25:21.029576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['content_1'] = train[['content_debertav3base', 'content_robertalarge', 'content_debertav3large', 'content_debertav3huge']].mean(axis=1)\n",
    "train['wording_1'] = train[['wording_debertav3base', 'wording_debertav3large', 'wording_robertalarge', 'wording_debertav3huge']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc23bc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T08:25:21.079855Z",
     "iopub.status.busy": "2023-10-11T08:25:21.079679Z",
     "iopub.status.idle": "2023-10-11T08:25:21.083753Z",
     "shell.execute_reply": "2023-10-11T08:25:21.082949Z"
    },
    "papermill": {
     "duration": 0.018694,
     "end_time": "2023-10-11T08:25:21.085384",
     "exception": false,
     "start_time": "2023-10-11T08:25:21.066690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2054c157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T08:25:21.111428Z",
     "iopub.status.busy": "2023-10-11T08:25:21.110545Z",
     "iopub.status.idle": "2023-10-11T08:25:21.120014Z",
     "shell.execute_reply": "2023-10-11T08:25:21.118950Z"
    },
    "papermill": {
     "duration": 0.024185,
     "end_time": "2023-10-11T08:25:21.121651",
     "exception": false,
     "start_time": "2023-10-11T08:25:21.097466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv mcrmse: 0.5403957243191679\n"
     ]
    }
   ],
   "source": [
    "mcrmse = compt_score(content_true=train[\"content\"], \n",
    "            content_pred=train[\"content_1\"], \n",
    "            wording_true=train[\"wording\"],\n",
    "            wording_pred=train[\"wording_1\"], \n",
    "           )\n",
    "print(f\"cv mcrmse: {mcrmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f832469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T08:25:21.148087Z",
     "iopub.status.busy": "2023-10-11T08:25:21.147334Z",
     "iopub.status.idle": "2023-10-11T08:25:21.153177Z",
     "shell.execute_reply": "2023-10-11T08:25:21.152433Z"
    },
    "papermill": {
     "duration": 0.0207,
     "end_time": "2023-10-11T08:25:21.154746",
     "exception": false,
     "start_time": "2023-10-11T08:25:21.134046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['content'] = test[['content_debertav3base', 'content_robertalarge', 'content_debertav3large', 'content_debertav3huge']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f714b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T08:25:21.180274Z",
     "iopub.status.busy": "2023-10-11T08:25:21.179837Z",
     "iopub.status.idle": "2023-10-11T08:25:21.185721Z",
     "shell.execute_reply": "2023-10-11T08:25:21.184998Z"
    },
    "papermill": {
     "duration": 0.020534,
     "end_time": "2023-10-11T08:25:21.187399",
     "exception": false,
     "start_time": "2023-10-11T08:25:21.166865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['wording'] = test[['wording_debertav3base', 'wording_debertav3large', 'wording_robertalarge', 'wording_debertav3huge']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583c3ec",
   "metadata": {
    "papermill": {
     "duration": 0.012212,
     "end_time": "2023-10-11T08:25:21.211854",
     "exception": false,
     "start_time": "2023-10-11T08:25:21.199642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c63e78cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T08:25:21.237860Z",
     "iopub.status.busy": "2023-10-11T08:25:21.237163Z",
     "iopub.status.idle": "2023-10-11T08:25:21.253619Z",
     "shell.execute_reply": "2023-10-11T08:25:21.252711Z"
    },
    "papermill": {
     "duration": 0.031287,
     "end_time": "2023-10-11T08:25:21.255429",
     "exception": false,
     "start_time": "2023-10-11T08:25:21.224142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2568.509017,
   "end_time": "2023-10-11T08:25:25.185401",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-11T07:42:36.676384",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
