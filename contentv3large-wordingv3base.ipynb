{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034094d3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-08T12:35:16.631850Z",
     "iopub.status.busy": "2023-10-08T12:35:16.630883Z",
     "iopub.status.idle": "2023-10-08T12:36:22.795091Z",
     "shell.execute_reply": "2023-10-08T12:36:22.793939Z"
    },
    "papermill": {
     "duration": 66.173527,
     "end_time": "2023-10-08T12:36:22.797326",
     "exception": false,
     "start_time": "2023-10-08T12:35:16.623799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\r\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622383 sha256=13e53890a9ee072321a5739e906356e6a07869e422eb303957ad092062b6184d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/69/42/0fb0421d2fe70d195a04665edc760cfe5fd341d7bb8d8e0aaa\r\n",
      "Successfully built autocorrect\r\n",
      "Installing collected packages: autocorrect\r\n",
      "Successfully installed autocorrect-2.6.1\r\n",
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8835ff60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:22.810823Z",
     "iopub.status.busy": "2023-10-08T12:36:22.810498Z",
     "iopub.status.idle": "2023-10-08T12:36:39.634333Z",
     "shell.execute_reply": "2023-10-08T12:36:39.633488Z"
    },
    "papermill": {
     "duration": 16.833193,
     "end_time": "2023-10-08T12:36:39.636688",
     "exception": false,
     "start_time": "2023-10-08T12:36:22.803495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from spellchecker import SpellChecker\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "disable_progress_bar()\n",
    "tqdm.pandas()\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1bdf46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:39.650073Z",
     "iopub.status.busy": "2023-10-08T12:36:39.649591Z",
     "iopub.status.idle": "2023-10-08T12:36:39.654676Z",
     "shell.execute_reply": "2023-10-08T12:36:39.653900Z"
    },
    "papermill": {
     "duration": 0.01357,
     "end_time": "2023-10-08T12:36:39.656533",
     "exception": false,
     "start_time": "2023-10-08T12:36:39.642963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name=\"debertav3large\"\n",
    "    learning_rate=0.000015  #0.000015\n",
    "    weight_decay=0.03        #0.02\n",
    "    hidden_dropout_prob=0.1\n",
    "    attention_probs_dropout_prob=0.1\n",
    "    num_train_epochs=5\n",
    "    n_splits=4\n",
    "    batch_size=12\n",
    "    random_seed=42\n",
    "    save_steps=100\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1b6b1",
   "metadata": {
    "papermill": {
     "duration": 0.005488,
     "end_time": "2023-10-08T12:36:39.667654",
     "exception": false,
     "start_time": "2023-10-08T12:36:39.662166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a41bf2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:39.680373Z",
     "iopub.status.busy": "2023-10-08T12:36:39.679720Z",
     "iopub.status.idle": "2023-10-08T12:36:39.791197Z",
     "shell.execute_reply": "2023-10-08T12:36:39.790290Z"
    },
    "papermill": {
     "duration": 0.120041,
     "end_time": "2023-10-08T12:36:39.793330",
     "exception": false,
     "start_time": "2023-10-08T12:36:39.673289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8b9bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:39.806535Z",
     "iopub.status.busy": "2023-10-08T12:36:39.806335Z",
     "iopub.status.idle": "2023-10-08T12:36:40.969106Z",
     "shell.execute_reply": "2023-10-08T12:36:40.968212Z"
    },
    "papermill": {
     "duration": 1.171938,
     "end_time": "2023-10-08T12:36:40.971313",
     "exception": false,
     "start_time": "2023-10-08T12:36:39.799375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                ) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.twd = TreebankWordDetokenizer()\n",
    "        self.STOP_WORDS = set(stopwords.words('english'))\n",
    "        \n",
    "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
    "        self.speller = Speller(lang='en')\n",
    "        self.spellchecker = SpellChecker() \n",
    "        \n",
    "    def word_overlap_count(self, row):\n",
    "        \"\"\" intersection(prompt_text, text) \"\"\"        \n",
    "        def check_is_stop_word(word):\n",
    "            return word in self.STOP_WORDS\n",
    "        \n",
    "        prompt_words = row['prompt_tokens']\n",
    "        summary_words = row['summary_tokens']\n",
    "        if self.STOP_WORDS:\n",
    "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "            \n",
    "    def ngrams(self, token, n):\n",
    "        # Use the zip function to help us generate n-grams\n",
    "        # Concatentate the tokens into ngrams and return\n",
    "        ngrams = zip(*[token[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "    def ngram_co_occurrence(self, row, n: int) -> int:\n",
    "        # Tokenize the original text and summary into words\n",
    "        original_tokens = row['prompt_tokens']\n",
    "        summary_tokens = row['summary_tokens']\n",
    "\n",
    "        # Generate n-grams for the original text and summary\n",
    "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
    "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
    "\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
    "        return len(common_ngrams)\n",
    "    \n",
    "    def ner_overlap_count(self, row, mode:str):\n",
    "        model = self.spacy_ner_model\n",
    "        def clean_ners(ner_list):\n",
    "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
    "        prompt = model(row['prompt_text'])\n",
    "        summary = model(row['text'])\n",
    "\n",
    "        if \"spacy\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
    "        elif \"stanza\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
    "        else:\n",
    "            raise Exception(\"Model not supported\")\n",
    "\n",
    "        prompt_ner = clean_ners(prompt_ner)\n",
    "        summary_ner = clean_ners(summary_ner)\n",
    "\n",
    "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
    "        \n",
    "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            return ner_dict\n",
    "        elif mode == \"test\":\n",
    "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
    "\n",
    "    \n",
    "    def quotes_count(self, row):\n",
    "        summary = row['text']\n",
    "        text = row['prompt_text']\n",
    "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
    "        if len(quotes_from_summary)>0:\n",
    "            return [quote in text for quote in quotes_from_summary].count(True)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def spelling(self, text):\n",
    "        \n",
    "        wordlist=text.split()\n",
    "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
    "\n",
    "        return amount_miss\n",
    "    \n",
    "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
    "        self.spellchecker.word_frequency.load_words(tokens)\n",
    "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
    "    \n",
    "    def run(self, \n",
    "            prompts: pd.DataFrame,\n",
    "            summaries:pd.DataFrame,\n",
    "            mode:str\n",
    "        ) -> pd.DataFrame:\n",
    "        \n",
    "        # before merge preprocess\n",
    "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "\n",
    "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "        \n",
    "        # Add prompt tokens into spelling checker dictionary\n",
    "        prompts[\"prompt_tokens\"].apply(\n",
    "            lambda x: self.add_spelling_dictionary(x)\n",
    "        )\n",
    "        \n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        # fix misspelling\n",
    "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n",
    "            lambda x: self.speller(x)\n",
    "        )\n",
    "        \n",
    "        # count misspelling\n",
    "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
    "        \n",
    "        # merge prompts and summaries\n",
    "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # after merge preprocess\n",
    "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
    "        \n",
    "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
    "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence,args=(2,), axis=1 \n",
    "        )\n",
    "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
    "        \n",
    "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence, args=(3,), axis=1\n",
    "        )\n",
    "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
    "        \n",
    "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
    "        \n",
    "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
    "    \n",
    "preprocessor = Preprocessor(model_name=CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc766f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:40.984849Z",
     "iopub.status.busy": "2023-10-08T12:36:40.984629Z",
     "iopub.status.idle": "2023-10-08T12:36:41.797695Z",
     "shell.execute_reply": "2023-10-08T12:36:41.796634Z"
    },
    "papermill": {
     "duration": 0.821751,
     "end_time": "2023-10-08T12:36:41.799429",
     "exception": false,
     "start_time": "2023-10-08T12:36:40.977678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3305.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 5787.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2015.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2818.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2417.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2153.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n",
    "train = pd.read_csv('/kaggle/input/pre-process/train.csv')\n",
    "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55466b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:41.813934Z",
     "iopub.status.busy": "2023-10-08T12:36:41.813741Z",
     "iopub.status.idle": "2023-10-08T12:36:41.825115Z",
     "shell.execute_reply": "2023-10-08T12:36:41.824623Z"
    },
    "papermill": {
     "duration": 0.020376,
     "end_time": "2023-10-08T12:36:41.826652",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.806276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30c6e9",
   "metadata": {
    "papermill": {
     "duration": 0.006934,
     "end_time": "2023-10-08T12:36:41.840077",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.833143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac351c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:41.853965Z",
     "iopub.status.busy": "2023-10-08T12:36:41.853525Z",
     "iopub.status.idle": "2023-10-08T12:36:41.858943Z",
     "shell.execute_reply": "2023-10-08T12:36:41.858067Z"
    },
    "papermill": {
     "duration": 0.014242,
     "end_time": "2023-10-08T12:36:41.860613",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.846371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104323f",
   "metadata": {
    "papermill": {
     "duration": 0.00622,
     "end_time": "2023-10-08T12:36:41.873506",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.867286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deberta Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9571d8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:41.887517Z",
     "iopub.status.busy": "2023-10-08T12:36:41.887329Z",
     "iopub.status.idle": "2023-10-08T12:36:41.897751Z",
     "shell.execute_reply": "2023-10-08T12:36:41.896955Z"
    },
    "papermill": {
     "duration": 0.019512,
     "end_time": "2023-10-08T12:36:41.899407",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.879895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentScoreRegressor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                model_dir: str,\n",
    "                target: str,\n",
    "                hidden_dropout_prob: float,\n",
    "                attention_probs_dropout_prob: float,\n",
    "                max_length: int,\n",
    "                ):\n",
    "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
    "        self.input_col = \"input\"\n",
    "        \n",
    "        self.text_cols = [self.input_col] \n",
    "        self.target = target\n",
    "        self.target_cols = [target]\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        \n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
    "            \"num_labels\": 1,\n",
    "            \"problem_type\": \"regression\",\n",
    "        })\n",
    "        \n",
    "        seed_everything(seed=42)\n",
    "\n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[self.target]]\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return tokenized\n",
    "\n",
    "        \n",
    "    def predict(self, \n",
    "                test_df: pd.DataFrame,\n",
    "                fold: int,\n",
    "               ):\n",
    "        \"\"\"predict content score\"\"\"\n",
    "        \n",
    "        sep = self.tokenizer.sep_token\n",
    "        in_text = (\n",
    "                    test_df[\"prompt_title\"] + sep \n",
    "                    + test_df[\"prompt_question\"] + sep \n",
    "                    + test_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        test_df[self.input_col] = in_text\n",
    "\n",
    "        test_ = test_df[[self.input_col]]\n",
    "    \n",
    "        test_dataset = Dataset.from_pandas(test_, preserve_index=False) \n",
    "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
    "        model_content.eval()\n",
    "        \n",
    "        # e.g. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train = False,\n",
    "            do_predict = True,\n",
    "            per_device_eval_batch_size = 4,   \n",
    "            dataloader_drop_last = False,\n",
    "        )\n",
    "\n",
    "        # init trainer\n",
    "        infer_content = Trainer(\n",
    "                      model = model_content, \n",
    "                      tokenizer=self.tokenizer,\n",
    "                      data_collator=self.data_collator,\n",
    "                      args = test_args)\n",
    "\n",
    "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff03914f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:41.913782Z",
     "iopub.status.busy": "2023-10-08T12:36:41.913354Z",
     "iopub.status.idle": "2023-10-08T12:36:41.921713Z",
     "shell.execute_reply": "2023-10-08T12:36:41.920959Z"
    },
    "papermill": {
     "duration": 0.017519,
     "end_time": "2023-10-08T12:36:41.923413",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.905894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"predict oof data\"\"\"\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        if model_name ==\"debertav3large\":\n",
    "            \n",
    "            model_dir =  f\"/kaggle/input/debertav3large-{target}-fold-{fold}/{target}/\"\n",
    "        if model_name ==\"debertav3base\":\n",
    "            model_dir=f\"/kaggle/input/wording-pb0-446/debertav3base/fold_{fold}\"\n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=valid_data, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
    "\n",
    "    return train_df\n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ):\n",
    "    \"\"\"predict using mean folds\"\"\"\n",
    "    #模型名称是model_name\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        if model_name ==\"debertav3large\":\n",
    "            model_dir =  f\"/kaggle/input/debertav3large-{target}-fold-{fold}/{target}/\"\n",
    "        if model_name ==\"debertav3base\":\n",
    "            model_dir=f\"/kaggle/input/wording-pb0-446/debertav3base/fold_{fold}\"\n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=test_df, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
    "    \n",
    "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87beb78b",
   "metadata": {
    "papermill": {
     "duration": 0.006305,
     "end_time": "2023-10-08T12:36:41.936492",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.930187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型推断部分 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15be5a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:36:41.950806Z",
     "iopub.status.busy": "2023-10-08T12:36:41.950139Z",
     "iopub.status.idle": "2023-10-08T12:42:41.062997Z",
     "shell.execute_reply": "2023-10-08T12:42:41.062069Z"
    },
    "papermill": {
     "duration": 359.122268,
     "end_time": "2023-10-08T12:42:41.065119",
     "exception": false,
     "start_time": "2023-10-08T12:36:41.942851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv content rmse: 0.450741654586165\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for target in [\"content\"]:\n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=False,\n",
    "        model_name=CFG.model_name,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=False,\n",
    "        model_name=CFG.model_name,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15537135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:42:41.081580Z",
     "iopub.status.busy": "2023-10-08T12:42:41.081359Z",
     "iopub.status.idle": "2023-10-08T12:42:41.085376Z",
     "shell.execute_reply": "2023-10-08T12:42:41.084522Z"
    },
    "papermill": {
     "duration": 0.014178,
     "end_time": "2023-10-08T12:42:41.087121",
     "exception": false,
     "start_time": "2023-10-08T12:42:41.072943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG.model_name1 = \"debertav3base\"\n",
    "CFG.hidden_dropout_prob=0.007\n",
    "CFG.attention_probs_dropout_prob=0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abfc1e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:42:41.103846Z",
     "iopub.status.busy": "2023-10-08T12:42:41.103023Z",
     "iopub.status.idle": "2023-10-08T12:44:40.949294Z",
     "shell.execute_reply": "2023-10-08T12:44:40.948383Z"
    },
    "papermill": {
     "duration": 119.857026,
     "end_time": "2023-10-08T12:44:40.951369",
     "exception": false,
     "start_time": "2023-10-08T12:42:41.094343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv wording rmse: 0.6314258139133476\n",
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for target in [\"wording\"]:\n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=False,\n",
    "        model_name=CFG.model_name1,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=False,\n",
    "        model_name=CFG.model_name1,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffbb725f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:40.969597Z",
     "iopub.status.busy": "2023-10-08T12:44:40.969358Z",
     "iopub.status.idle": "2023-10-08T12:44:40.974232Z",
     "shell.execute_reply": "2023-10-08T12:44:40.973445Z"
    },
    "papermill": {
     "duration": 0.016094,
     "end_time": "2023-10-08T12:44:40.976111",
     "exception": false,
     "start_time": "2023-10-08T12:44:40.960017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['student_id', 'prompt_id', 'text', 'summary_length',\n",
      "       'fixed_summary_text', 'splling_err_num', 'prompt_question',\n",
      "       'prompt_title', 'prompt_text', 'prompt_length', 'length_ratio',\n",
      "       'word_overlap_count', 'bigram_overlap_count', 'bigram_overlap_ratio',\n",
      "       'trigram_overlap_count', 'trigram_overlap_ratio', 'quotes_count',\n",
      "       'input', 'content_pred_0', 'content_pred_1', 'content_pred_2',\n",
      "       'content_pred_3', 'content', 'wording_pred_0', 'wording_pred_1',\n",
      "       'wording_pred_2', 'wording_pred_3', 'wording'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436271d9",
   "metadata": {
    "papermill": {
     "duration": 0.008096,
     "end_time": "2023-10-08T12:44:40.992675",
     "exception": false,
     "start_time": "2023-10-08T12:44:40.984579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7cf1ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:41.010387Z",
     "iopub.status.busy": "2023-10-08T12:44:41.010183Z",
     "iopub.status.idle": "2023-10-08T12:44:41.014174Z",
     "shell.execute_reply": "2023-10-08T12:44:41.013338Z"
    },
    "papermill": {
     "duration": 0.014765,
     "end_time": "2023-10-08T12:44:41.015811",
     "exception": false,
     "start_time": "2023-10-08T12:44:41.001046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = [\"content\", \"wording\"]\n",
    "\n",
    "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\"\n",
    "               ] + targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7697817b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:41.033702Z",
     "iopub.status.busy": "2023-10-08T12:44:41.033072Z",
     "iopub.status.idle": "2023-10-08T12:44:41.847324Z",
     "shell.execute_reply": "2023-10-08T12:44:41.846373Z"
    },
    "papermill": {
     "duration": 0.825196,
     "end_time": "2023-10-08T12:44:41.849139",
     "exception": false,
     "start_time": "2023-10-08T12:44:41.023943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.406133\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttrain's rmse: 0.405381\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.461477\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttrain's rmse: 0.458761\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttrain's rmse: 0.434164\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.484789\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttrain's rmse: 0.482948\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.518114\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttrain's rmse: 0.518082\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttrain's rmse: 0.651634\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttrain's rmse: 0.494291\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.648034\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttrain's rmse: 0.646784\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for target in targets:\n",
    "    models = []\n",
    "    \n",
    "    for fold in range(CFG.n_splits):\n",
    "\n",
    "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
    "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
    "\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
    "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
    "\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': 42,\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': 0.048,\n",
    "            'max_depth': 4,  #3\n",
    "            'lambda_l1': 0.0,\n",
    "            'lambda_l2': 0.011,\n",
    "            'verbose':-1\n",
    "        }\n",
    "\n",
    "        evaluation_results = {}\n",
    "        model = lgb.train(params,\n",
    "                          num_boost_round=10000,\n",
    "                            #categorical_feature = categorical_features,\n",
    "                          valid_names=['train', 'valid'],\n",
    "                          train_set=dtrain,\n",
    "                          valid_sets=dval,\n",
    "                          callbacks=[\n",
    "                              lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
    "                               lgb.log_evaluation(100),\n",
    "                              lgb.callback.record_evaluation(evaluation_results)\n",
    "                            ],\n",
    "                          )\n",
    "        models.append(model)\n",
    "    \n",
    "    model_dict[target] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42659ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:41.868069Z",
     "iopub.status.busy": "2023-10-08T12:44:41.867873Z",
     "iopub.status.idle": "2023-10-08T12:44:41.944831Z",
     "shell.execute_reply": "2023-10-08T12:44:41.943992Z"
    },
    "papermill": {
     "duration": 0.088322,
     "end_time": "2023-10-08T12:44:41.946532",
     "exception": false,
     "start_time": "2023-10-08T12:44:41.858210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_rmse : 0.44114233808626113\n",
      "wording_rmse : 0.5732193623542492\n",
      "mcrmse : 0.5071808502202552\n"
     ]
    }
   ],
   "source": [
    "# cv\n",
    "rmses = []\n",
    "\n",
    "for target in targets:\n",
    "    models = model_dict[target]\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    for fold, model in enumerate(models):\n",
    "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "        pred = model.predict(X_eval_cv)\n",
    "\n",
    "        trues.extend(y_eval_cv)\n",
    "        preds.extend(pred)\n",
    "        \n",
    "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "    print(f\"{target}_rmse : {rmse}\")\n",
    "    rmses = rmses + [rmse]\n",
    "\n",
    "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a31458",
   "metadata": {
    "papermill": {
     "duration": 0.008709,
     "end_time": "2023-10-08T12:44:41.964208",
     "exception": false,
     "start_time": "2023-10-08T12:44:41.955499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28b6a88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:41.983157Z",
     "iopub.status.busy": "2023-10-08T12:44:41.982404Z",
     "iopub.status.idle": "2023-10-08T12:44:41.987351Z",
     "shell.execute_reply": "2023-10-08T12:44:41.986606Z"
    },
    "papermill": {
     "duration": 0.016061,
     "end_time": "2023-10-08T12:44:41.988957",
     "exception": false,
     "start_time": "2023-10-08T12:44:41.972896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "                \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\",\n",
    "                \"input\"\n",
    "               ] + [\n",
    "                f\"content_pred_{i}\" for i in range(CFG.n_splits)\n",
    "                ] + [\n",
    "                f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n",
    "                ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f074c7f",
   "metadata": {
    "papermill": {
     "duration": 0.008344,
     "end_time": "2023-10-08T12:44:42.005708",
     "exception": false,
     "start_time": "2023-10-08T12:44:41.997364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 使用LGB进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb1710a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:42.023912Z",
     "iopub.status.busy": "2023-10-08T12:44:42.023711Z",
     "iopub.status.idle": "2023-10-08T12:44:42.039272Z",
     "shell.execute_reply": "2023-10-08T12:44:42.038436Z"
    },
    "papermill": {
     "duration": 0.026787,
     "end_time": "2023-10-08T12:44:42.041022",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.014235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pred_dict = {}  # 创建一个空字典，用于存储预测结果\n",
    "for target in targets:  \n",
    "    models = model_dict[target]  # 获取当前目标的模型列表\n",
    "    preds = []  # 创建一个空列表，用于存储预测结果\n",
    "    for fold, model in enumerate(models):  # 遍历当前目标的每个折中的模型\n",
    "        X_eval_cv = test.drop(columns=drop_columns)  # 获取测试数据，并删除不需要的列\n",
    "        pred = model.predict(X_eval_cv)  # 对测试数据进行预测#LGB\n",
    "        preds.append(pred)  # 将预测结果添加到列表中\n",
    "    pred_dict[target] = preds  # 将当前目标的预测结果列表存储到预测字典中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1cf5ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:42.060558Z",
     "iopub.status.busy": "2023-10-08T12:44:42.060355Z",
     "iopub.status.idle": "2023-10-08T12:44:42.067303Z",
     "shell.execute_reply": "2023-10-08T12:44:42.066334Z"
    },
    "papermill": {
     "duration": 0.019066,
     "end_time": "2023-10-08T12:44:42.069109",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.050043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': [array([-1.43065547, -1.43065547, -1.43065547, -1.43065547]),\n",
       "  array([-1.46317498, -1.46317498, -1.46317498, -1.46317498]),\n",
       "  array([-1.27218108, -1.27218108, -1.27218108, -1.27218108]),\n",
       "  array([-1.67978803, -1.67978803, -1.67978803, -1.67978803])],\n",
       " 'wording': [array([-1.42854343, -1.42854343, -1.42854343, -1.42854343]),\n",
       "  array([-1.13835604, -1.13835604, -1.13835604, -1.13835604]),\n",
       "  array([-1.22084585, -1.22084585, -1.22084585, -1.22084585]),\n",
       "  array([-1.44926424, -1.44926424, -1.44926424, -1.44926424])]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a230293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:42.089923Z",
     "iopub.status.busy": "2023-10-08T12:44:42.089215Z",
     "iopub.status.idle": "2023-10-08T12:44:42.100077Z",
     "shell.execute_reply": "2023-10-08T12:44:42.099305Z"
    },
    "papermill": {
     "duration": 0.023156,
     "end_time": "2023-10-08T12:44:42.101962",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.078806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for target in targets:  # 遍历目标列表中的每一个目标\n",
    "    preds = pred_dict[target]  # 获取当前目标的预测结果列表#LGB的预测结果\n",
    "    \n",
    "    for i, pred in enumerate(preds):  # 遍历当前目标的每个折中的预测结果\n",
    "        test[f\"{target}_pred_{i}\"] = pred  # 将预测结果添加到测试数据中，创建新的列名\n",
    "    test[f'{target}'] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30d49329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:42.121896Z",
     "iopub.status.busy": "2023-10-08T12:44:42.121117Z",
     "iopub.status.idle": "2023-10-08T12:44:42.144539Z",
     "shell.execute_reply": "2023-10-08T12:44:42.143704Z"
    },
    "papermill": {
     "duration": 0.035166,
     "end_time": "2023-10-08T12:44:42.146196",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.111030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>fixed_summary_text</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>...</th>\n",
       "      <th>content_pred_0</th>\n",
       "      <th>content_pred_1</th>\n",
       "      <th>content_pred_2</th>\n",
       "      <th>content_pred_3</th>\n",
       "      <th>content</th>\n",
       "      <th>wording_pred_0</th>\n",
       "      <th>wording_pred_1</th>\n",
       "      <th>wording_pred_2</th>\n",
       "      <th>wording_pred_3</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 1</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 2</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 2</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 3</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 3</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 4</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 4</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id            text  summary_length fixed_summary_text  \\\n",
       "0  000000ffffff    abc123  Example text 1               3     Example text 1   \n",
       "1  111111eeeeee    def789  Example text 2               3     Example text 2   \n",
       "2  222222cccccc    abc123  Example text 3               3     Example text 3   \n",
       "3  333333dddddd    def789  Example text 4               3     Example text 4   \n",
       "\n",
       "   splling_err_num prompt_question     prompt_title       prompt_text  \\\n",
       "0                0    Summarize...  Example Title 1  Heading\\nText...   \n",
       "1                0    Summarize...  Example Title 2  Heading\\nText...   \n",
       "2                0    Summarize...  Example Title 1  Heading\\nText...   \n",
       "3                0    Summarize...  Example Title 2  Heading\\nText...   \n",
       "\n",
       "   prompt_length  ...  content_pred_0  content_pred_1  content_pred_2  \\\n",
       "0              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "1              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "2              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "3              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "\n",
       "   content_pred_3  content  wording_pred_0  wording_pred_1 wording_pred_2  \\\n",
       "0       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "1       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "2       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "3       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "\n",
       "   wording_pred_3   wording  \n",
       "0       -1.449264 -1.309252  \n",
       "1       -1.449264 -1.309252  \n",
       "2       -1.449264 -1.309252  \n",
       "3       -1.449264 -1.309252  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7669636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:42.166478Z",
     "iopub.status.busy": "2023-10-08T12:44:42.165864Z",
     "iopub.status.idle": "2023-10-08T12:44:42.185478Z",
     "shell.execute_reply": "2023-10-08T12:44:42.184463Z"
    },
    "papermill": {
     "duration": 0.032183,
     "end_time": "2023-10-08T12:44:42.187324",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.155141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>fixed_summary_text</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>...</th>\n",
       "      <th>content_pred_0</th>\n",
       "      <th>content_pred_1</th>\n",
       "      <th>content_pred_2</th>\n",
       "      <th>content_pred_3</th>\n",
       "      <th>content</th>\n",
       "      <th>wording_pred_0</th>\n",
       "      <th>wording_pred_1</th>\n",
       "      <th>wording_pred_2</th>\n",
       "      <th>wording_pred_3</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 1</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 2</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 2</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>abc123</td>\n",
       "      <td>Example text 3</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 3</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 1</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>def789</td>\n",
       "      <td>Example text 4</td>\n",
       "      <td>3</td>\n",
       "      <td>Example text 4</td>\n",
       "      <td>0</td>\n",
       "      <td>Summarize...</td>\n",
       "      <td>Example Title 2</td>\n",
       "      <td>Heading\\nText...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430655</td>\n",
       "      <td>-1.463175</td>\n",
       "      <td>-1.272181</td>\n",
       "      <td>-1.679788</td>\n",
       "      <td>-1.46145</td>\n",
       "      <td>-1.428543</td>\n",
       "      <td>-1.138356</td>\n",
       "      <td>-1.220846</td>\n",
       "      <td>-1.449264</td>\n",
       "      <td>-1.309252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id            text  summary_length fixed_summary_text  \\\n",
       "0  000000ffffff    abc123  Example text 1               3     Example text 1   \n",
       "1  111111eeeeee    def789  Example text 2               3     Example text 2   \n",
       "2  222222cccccc    abc123  Example text 3               3     Example text 3   \n",
       "3  333333dddddd    def789  Example text 4               3     Example text 4   \n",
       "\n",
       "   splling_err_num prompt_question     prompt_title       prompt_text  \\\n",
       "0                0    Summarize...  Example Title 1  Heading\\nText...   \n",
       "1                0    Summarize...  Example Title 2  Heading\\nText...   \n",
       "2                0    Summarize...  Example Title 1  Heading\\nText...   \n",
       "3                0    Summarize...  Example Title 2  Heading\\nText...   \n",
       "\n",
       "   prompt_length  ...  content_pred_0  content_pred_1  content_pred_2  \\\n",
       "0              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "1              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "2              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "3              3  ...       -1.430655       -1.463175       -1.272181   \n",
       "\n",
       "   content_pred_3  content  wording_pred_0  wording_pred_1 wording_pred_2  \\\n",
       "0       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "1       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "2       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "3       -1.679788 -1.46145       -1.428543       -1.138356      -1.220846   \n",
       "\n",
       "   wording_pred_3   wording  \n",
       "0       -1.449264 -1.309252  \n",
       "1       -1.449264 -1.309252  \n",
       "2       -1.449264 -1.309252  \n",
       "3       -1.449264 -1.309252  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca887ea",
   "metadata": {
    "papermill": {
     "duration": 0.009321,
     "end_time": "2023-10-08T12:44:42.206835",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.197514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "838fed26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T12:44:42.227177Z",
     "iopub.status.busy": "2023-10-08T12:44:42.226393Z",
     "iopub.status.idle": "2023-10-08T12:44:42.236286Z",
     "shell.execute_reply": "2023-10-08T12:44:42.235438Z"
    },
    "papermill": {
     "duration": 0.021954,
     "end_time": "2023-10-08T12:44:42.238087",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.216133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bf6c9",
   "metadata": {
    "papermill": {
     "duration": 0.009406,
     "end_time": "2023-10-08T12:44:42.257517",
     "exception": false,
     "start_time": "2023-10-08T12:44:42.248111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 577.768667,
   "end_time": "2023-10-08T12:44:45.706907",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-08T12:35:07.938240",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
